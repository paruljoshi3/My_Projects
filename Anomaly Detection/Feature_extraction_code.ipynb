{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06007265",
   "metadata": {},
   "source": [
    "# Feature extraction CODE FOR PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd9f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cart.lab2\\AppData\\Local\\Temp\\ipykernel_8312\\2381300825.py:65: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  features_tensor = torch.tensor(features)\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Define the paths\n",
    "dataset_path = \"C:/Users/cart.lab2/dataset1\" #Root directory of the dataset\n",
    "output_path = \"C:/Users/cart.lab2/Frames\" #Directory to save the extracted frames\n",
    "features_path = \"C:/Users/cart.lab2/features.pt\" #Path to save the extracted features as tensors\n",
    "labels_path = \"C:/Users/cart.lab2/labels.txt\" #Path to save the labels as a text file\n",
    "\n",
    "# Create the ResNet50 model\n",
    "model = resnet50(pretrained=True) # Load the pre-trained ResNet-50 model\n",
    "model = model.eval() # Set the model to evaluation mode (no gradient computation)\n",
    "\n",
    "# Define a sequence of transformations to be applied to each frame\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "features = [] #List to store the extracted features from frames\n",
    "labels = [] #List o store the corresponding labels(Anomaly or Normal)\n",
    "\n",
    "# Iterate over the folders\n",
    "for folder_name in [\"Anomaly\", \"Normal\"]:\n",
    "    folder_path = os.path.join(dataset_path, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate over the videos in the folder\n",
    "    video_files = os.listdir(folder_path)\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(folder_path, video_file)\n",
    "\n",
    "        # Open the video file\n",
    "        video_capture = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT)) # Get the total number of frames in the video\n",
    "\n",
    "        # Extract frames and features\n",
    "        for frame_index in range(frame_count):\n",
    "            success, frame = video_capture.read() # Read the next frame from the video\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # Extract features using ResNet50\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # Convert frame from BGR to RGB (as ResNet-50 expects RGB)\n",
    "            frame_tensor = transform(frame) # Apply the defined transformations to the frame\n",
    "            frame_tensor = torch.unsqueeze(frame_tensor, 0) # Add a batch dimension (required by ResNet-50)\n",
    "            with torch.no_grad():\n",
    "                feature_tensor = model(frame_tensor)  # Pass the frame through the ResNet-50 model\n",
    "\n",
    "            # Append features and labels\n",
    "            # Convert the feature tensor to a numpy array and append\n",
    "            features.append(feature_tensor.squeeze().numpy())\n",
    "            \n",
    "            # Append the corresponding label (Anomaly or Normal)\n",
    "            labels.append(folder_name)\n",
    "\n",
    "            # Save extracted frame\n",
    "            frame_output_path = os.path.join(output_path, f\"{folder_name}_{video_file}_{frame_index}.jpg\")\n",
    "            cv2.imwrite(frame_output_path, frame)\n",
    "\n",
    "        # Release the video capture object\n",
    "        video_capture.release()\n",
    "\n",
    "# Convert features to tensors\n",
    "features_tensor = torch.tensor(features)\n",
    "\n",
    "# Save features as tensors\n",
    "torch.save(features_tensor, features_path)\n",
    "\n",
    "# Save labels in a text file\n",
    "with open(labels_path, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(label + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6e0d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8009, -1.2275, -3.4029,  ..., -1.9273, -1.0958,  1.6958],\n",
       "        [-4.8076, -1.2441, -3.3980,  ..., -1.9423, -1.0766,  1.7222],\n",
       "        [-4.8022, -1.2364, -3.3939,  ..., -1.9411, -1.0752,  1.7155],\n",
       "        ...,\n",
       "        [-1.8786,  1.6181,  0.0378,  ..., -1.1894,  0.6525, -1.3284],\n",
       "        [-1.8312,  1.4049,  0.1747,  ..., -0.9394,  0.4374, -1.4905],\n",
       "        [-1.8601,  1.3853,  0.1716,  ..., -0.9265,  0.4233, -1.4928]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a8d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
