{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32efa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b087f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your data and labels as tensors\n",
    "features = torch.load('C:/Users/parul/KIST_Research_Paper/features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3ef937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8009, -1.2275, -3.4029,  ..., -1.9273, -1.0958,  1.6958],\n",
       "        [-4.8076, -1.2441, -3.3980,  ..., -1.9423, -1.0766,  1.7222],\n",
       "        [-4.8022, -1.2364, -3.3939,  ..., -1.9411, -1.0752,  1.7155],\n",
       "        ...,\n",
       "        [-1.8786,  1.6181,  0.0378,  ..., -1.1894,  0.6525, -1.3284],\n",
       "        [-1.8312,  1.4049,  0.1747,  ..., -0.9394,  0.4374, -1.4905],\n",
       "        [-1.8601,  1.3853,  0.1716,  ..., -0.9265,  0.4233, -1.4928]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8b9efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([94003, 1000])\n",
      "Size: torch.Size([94003, 1000])\n",
      "Length: 94003\n"
     ]
    }
   ],
   "source": [
    "# Access the shape, size, and length of the features tensor\n",
    "shape = features.shape\n",
    "size = features.size() # Get the dimensionality of the feature vectors\n",
    "length = len(features)\n",
    "\n",
    "print(\"Shape:\", shape)\n",
    "print(\"Size:\", size)\n",
    "print(\"Length:\", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b5fdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588c5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array Shape: (94003,)\n",
      "Array Contents: [1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels_path = \"C:/Users/parul/KIST_Research_Paper/labels.npy\"\n",
    "\n",
    "# Load the labels array from the .npy file\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Print the shape and contents of the loaded array\n",
    "print(\"Array Shape:\", labels.shape)\n",
    "print(\"Array Contents:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5017d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Load labels from npy file\n",
    "labels_np = np.load('C:/Users/parul/KIST_Research_Paper/labels.npy')\n",
    "\n",
    "# Convert labels to tensors\n",
    "labels = torch.from_numpy(labels_np)\n",
    "\n",
    "# Verify the type of the resulting tensor\n",
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7065c4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "Class 1.0: 71755 samples\n",
      "Class 0.0: 22248 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# Convert labels to NumPy array as they are tensors\n",
    "if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.numpy()\n",
    "\n",
    "# Count the occurrences of each class label\n",
    "class_counts = Counter(labels)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Class Distribution:\")\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af3d2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before Oversampling:\n",
      "Class 1.0: 71755 samples\n",
      "Class 0.0: 22248 samples\n",
      "\n",
      "Class Distribution After Oversampling:\n",
      "Class 1.0: 71755 samples\n",
      "Class 0.0: 71755 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.numpy()\n",
    "\n",
    "# Count the occurrences of each class label\n",
    "class_counts = Counter(labels)\n",
    "\n",
    "# Print class distribution before oversampling\n",
    "print(\"Class Distribution Before Oversampling:\")\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} samples\")\n",
    "\n",
    "# Create RandomOverSampler instance\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Reshape the dataset for the oversampler\n",
    "num_samples, num_features = features.shape\n",
    "features_reshaped = features.reshape(num_samples, -1)\n",
    "\n",
    "# Perform oversampling\n",
    "oversampled_features, oversampled_labels = oversampler.fit_resample(features_reshaped, labels)\n",
    "\n",
    "# Reshape back to the original shape\n",
    "oversampled_features = oversampled_features.reshape(-1, num_features)\n",
    "\n",
    "# Convert back to PyTorch tensors\n",
    "features = torch.tensor(oversampled_features)\n",
    "labels = torch.tensor(oversampled_labels)\n",
    "# \n",
    "# Count the occurrences of each class label after oversampling\n",
    "oversampled_class_counts = Counter(labels.numpy())\n",
    "\n",
    "# Print class distribution after oversampling\n",
    "print(\"\\nClass Distribution After Oversampling:\")\n",
    "for class_label, count in oversampled_class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50b89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7ab14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.3, random_state=42, shuffle = True)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.4, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f190e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2960, -1.4940, -1.8903,  ..., -2.6258, -0.0291, -0.6367],\n",
       "        [-4.3677, -1.4747,  0.3917,  ..., -3.2578, -0.0509, -0.0852],\n",
       "        [-1.9103, -0.2454, -2.6092,  ..., -2.1218,  0.1021,  2.2596],\n",
       "        ...,\n",
       "        [-2.2974, -1.3273, -2.2430,  ..., -1.9776, -0.2803, -0.9984],\n",
       "        [-0.9375, -0.2770, -3.0252,  ..., -2.5874,  0.5063,  0.8909],\n",
       "        [-1.7555, -0.7285, -2.4615,  ..., -2.2939, -0.2912, -1.2019]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2022f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036797a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = np.unique(y_train)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b84cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855c1585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9367430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is: \n",
      " torch.Size([100457, 1000])\n",
      "Y_train shape is: \n",
      " torch.Size([100457])\n",
      "\n",
      "X_val shape is: \n",
      " torch.Size([25831, 1000])\n",
      "Y_val shape is:\n",
      " torch.Size([25831])\n",
      "\n",
      "X_test shape is: \n",
      " torch.Size([17222, 1000])\n",
      "Y_test shape is: \n",
      " torch.Size([17222])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape is: \\n\", x_train.shape)\n",
    "print(\"Y_train shape is: \\n\", y_train.shape)\n",
    "print(\"\\nX_val shape is: \\n\", x_val.shape)\n",
    "print(\"Y_val shape is:\\n\", y_val.shape)\n",
    "print(\"\\nX_test shape is: \\n\", x_test.shape)\n",
    "print(\"Y_test shape is: \\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf9276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100457"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afade6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is: \n",
      " torch.Size([100457, 4, 25, 10])\n",
      "Y_train shape is: \n",
      " torch.Size([100457, 1])\n",
      "\n",
      "X_val shape is: \n",
      " torch.Size([25831, 4, 25, 10])\n",
      "Y_val shape is:\n",
      " torch.Size([25831, 1])\n",
      "\n",
      "X_test shape is: \n",
      " torch.Size([17222, 4, 25, 10])\n",
      "Y_test shape is: \n",
      " torch.Size([17222, 1])\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.view(100457, 4, 25, 10)\n",
    "y_train = y_train.view(100457,1)\n",
    "x_val = x_val.view(25831, 4, 25, 10)\n",
    "y_val = y_val.view(25831,1)\n",
    "x_test = x_test.view(17222, 4, 25, 10)\n",
    "y_test = y_test.view(17222,1)\n",
    "\n",
    "\n",
    "# Print the shapes of the train and test sets\n",
    "print(\"X_train shape is: \\n\", x_train.shape)\n",
    "print(\"Y_train shape is: \\n\", y_train.shape)\n",
    "print(\"\\nX_val shape is: \\n\", x_val.shape)\n",
    "print(\"Y_val shape is:\\n\", y_val.shape)\n",
    "print(\"\\nX_test shape is: \\n\", x_test.shape)\n",
    "print(\"Y_test shape is: \\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5fadeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.features[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "        #return self.features[index], self.labels[index]\n",
    "    \n",
    "class RelationAwareFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RelationAwareFeatureExtractor, self).__init__()\n",
    "\n",
    "        # ConvNet layers\n",
    "        self.conv1 = nn.Conv2d(4, 8, kernel_size=3, stride=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, stride=3, padding=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64*1*1, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 125)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # Flatten the tensor before fully connected layers\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten dimensions except batch dimension\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add an extra dimension for seq_len\n",
    "        x = x.unsqueeze(1)\n",
    "        batch_size, seq_len, hidden_size = x.size()\n",
    "\n",
    "        # Compute Query, Key, and Value matrices\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        # Compute attention scores\n",
    "        scores = torch.matmul(q, k.transpose(1, 2))\n",
    "        attention_weights = F.softmax(scores, dim=2)\n",
    "\n",
    "        # Compute the weighted sum of Value using attention weights\n",
    "        x = torch.matmul(attention_weights, v)\n",
    "\n",
    "        # Squeeze the extra seq_len dimension and return the result\n",
    "        x = x.squeeze(1)\n",
    "        return x\n",
    "\n",
    "class ConditionalRandomFields(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels):\n",
    "        super(ConditionalRandomFields, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size, num_labels)\n",
    "        self.linear2 = nn.Linear(num_labels, num_labels)\n",
    "        self.linear3 = nn.Linear(num_labels, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        #x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "class AnomalyDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnomalyDetector, self).__init__()\n",
    "        \n",
    "        # Feature extractor\n",
    "        self.feature_extractor = RelationAwareFeatureExtractor()\n",
    "\n",
    "        # Self-attention layer\n",
    "        self.self_attention = SelfAttention(125)\n",
    "\n",
    "        # Conditional random fields layer\n",
    "        self.conditional_random_fields = ConditionalRandomFields(125,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.self_attention(x)\n",
    "        log_likelihood = self.conditional_random_fields(x)\n",
    "\n",
    "        return log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6f741",
   "metadata": {},
   "source": [
    "#### Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20571e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models and move them to the desired device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9315015",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 125\n",
    "hidden_dim = 50\n",
    "output_dim = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5869643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train and test datasets\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "val_dataset = CustomDataset(x_val, y_val)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "# Define the train loader\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80055200",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0dbe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the AnomalyDetector\n",
    "model = AnomalyDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c92cb676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 8, 9, 4]             296\n",
      "         MaxPool2d-2              [-1, 8, 4, 2]               0\n",
      "            Conv2d-3             [-1, 16, 2, 1]           1,168\n",
      "           Dropout-4             [-1, 16, 2, 1]               0\n",
      "            Conv2d-5             [-1, 32, 1, 1]           4,640\n",
      "            Conv2d-6             [-1, 64, 1, 1]          18,496\n",
      "            Linear-7                 [-1, 1024]          66,560\n",
      "            Linear-8                  [-1, 256]         262,400\n",
      "            Linear-9                  [-1, 125]          32,125\n",
      "RelationAwareFeatureExtractor-10                  [-1, 125]               0\n",
      "           Linear-11               [-1, 1, 125]          15,750\n",
      "           Linear-12               [-1, 1, 125]          15,750\n",
      "           Linear-13               [-1, 1, 125]          15,750\n",
      "    SelfAttention-14                  [-1, 125]               0\n",
      "           Linear-15                    [-1, 2]             252\n",
      "           Linear-16                    [-1, 2]               6\n",
      "ConditionalRandomFields-17                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 433,193\n",
      "Trainable params: 433,193\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 1.65\n",
      "Estimated Total Size (MB): 1.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "# Move the model to the GPU if available\n",
    "model.to(device)\n",
    "summary(model, (4, 25, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "172b9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c10e8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(val_loss, patience=3):\n",
    "    if len(val_loss) <= patience:\n",
    "        return False\n",
    "    \n",
    "    for i in range(1, patience + 1):\n",
    "        if val_loss[-i] > val_loss[-i - 1]:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5869a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/20] | Train Loss: 0.5804 | Train Accuracy: 0.66\n",
      "Epoch [1/20] | Validation Loss: 0.3147 | Validation Accuracy: 0.81\n",
      "\n",
      "Epoch [2/20] | Train Loss: 0.3091 | Train Accuracy: 0.88\n",
      "Epoch [2/20] | Validation Loss: 0.2311 | Validation Accuracy: 0.91\n",
      "\n",
      "Epoch [3/20] | Train Loss: 0.2394 | Train Accuracy: 0.91\n",
      "Epoch [3/20] | Validation Loss: 0.1729 | Validation Accuracy: 0.96\n",
      "\n",
      "Epoch [4/20] | Train Loss: 0.1846 | Train Accuracy: 0.94\n",
      "Epoch [4/20] | Validation Loss: 0.1573 | Validation Accuracy: 0.96\n",
      "\n",
      "Epoch [5/20] | Train Loss: 0.1713 | Train Accuracy: 0.94\n",
      "Epoch [5/20] | Validation Loss: 0.1383 | Validation Accuracy: 0.97\n",
      "\n",
      "Epoch [6/20] | Train Loss: 0.1450 | Train Accuracy: 0.95\n",
      "Epoch [6/20] | Validation Loss: 0.1373 | Validation Accuracy: 0.96\n",
      "\n",
      "Epoch [7/20] | Train Loss: 0.1306 | Train Accuracy: 0.96\n",
      "Epoch [7/20] | Validation Loss: 0.2361 | Validation Accuracy: 0.92\n",
      "Early stopping triggered! \n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store accuracy values\n",
    "train_accuracy_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "val_loss_history = []\n",
    "train_loss_history = []\n",
    "verbose = True\n",
    "\n",
    "l2_lambda = 0.0001 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(batch_data)\n",
    "        \n",
    "        batch_labels = batch_labels.view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        ce_loss = criterion(output, batch_labels.long())\n",
    "        \n",
    "        l2_reg = 0.0\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param, p=2)\n",
    "\n",
    "        # Combine the cross-entropy loss and L2 regularization term\n",
    "        loss = ce_loss + l2_lambda * l2_reg\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += batch_labels.size(0)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    train_accuracy_history.append(accuracy)\n",
    "    train_loss_history.append(train_loss)\n",
    "    \n",
    "    if verbose: \n",
    "        print(f\"\\nEpoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Train Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_batch_data, val_batch_labels in val_loader:\n",
    "            outputs = model(val_batch_data)\n",
    "            labels = val_batch_labels.view(-1)\n",
    "            \n",
    "            # Compute loss\n",
    "            ce_val_loss = criterion(outputs, labels.long())\n",
    "        \n",
    "            l2_reg = 0.0\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param, p=2)\n",
    "\n",
    "            # Combine the cross-entropy loss and L2 regularization term\n",
    "            loss = ce_val_loss + l2_lambda * l2_reg\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += val_batch_labels.size(0)\n",
    "            val_correct += (predicted == val_batch_labels).sum().item()\n",
    "            \n",
    "        val_loss /=len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_accuracy_history.append(val_acc)\n",
    "        val_loss_history.append(val_loss)  \n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] | Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "    #Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if early_stopping(val_loss_history, patience):\n",
    "        print(\"Early stopping triggered! \")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a5d9d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy graph\n",
    "epochs = range(1, len(train_accuracy_history) + 1)\n",
    "\n",
    "plt.plot(epochs, train_accuracy_history, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy_history, 'r', labl='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b2d6169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2334 | Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():  # Turn off gradient tracking for testing\n",
    "    for test_batch_data, test_batch_labels in test_loader:\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(test_batch_data)\n",
    "        labels = test_batch_labels.view(-1)\n",
    "\n",
    "        test_loss += criterion(output, labels.long()).item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test_total += test_batch_labels.size(0)\n",
    "        test_correct += (predicted == test_batch_labels).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "791241d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, saving the model\n",
    "torch.save(model.state_dict(), 'anomaly_detector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f568c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b643ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa52e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
